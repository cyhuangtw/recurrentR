<!-- better looking
options(rstudio.markdownToHTML = 
  function(inputFile, outputFile) {      
    require(markdown)
    markdownToHTML(inputFile, outputFile, 
  stylesheet='combined.css'
    )
  }
) 
# pandoc -f markdown -sS --mathjax --toc -c ~/.vim/shareboard/css/combined.css -o WQC2001.html WQC2001.md
# --- using pandoc to output HTML --- #
# One can use either '--webtex' or '--mathjax' for preview
options(rstudio.markdownToHTML = 
  function(inputFile, outputFile) {      
    system(paste("pandoc", shQuote(inputFile), "--webtex", "--toc -sS", "-c", "combined.css", "-o", shQuote(outputFile)))
  }
)
-->

Implementation of Paper WQC 2001
================================

The Simplest Model (No Covariates)
----------------------------------
No Time-Dependent Variable $\mathbb{X}_i$ nor Time-Independent Variable $\mathbb{W}_i$ is involved.

Assume the random variable has PDF $f_i(t)$ 
$$
f_i(t) = \frac{\lambda_i(t)}{\Lambda_i(T_0)} = \cdots = \frac{\lambda_0(t)}{\Lambda_0(T_0)}
$$
which is invariant of $i$. CDF $F(t)$ is then 
$$
F(t) = \int^t_0f(u)du
$$
This random variable's CDF can be estimated by $\hat{F(t)}$, 
$$
\hat{F}(t) = \prod_{s(l) > t}(1-\frac{d(l)}{N(l)})
$$

* $l = 0, 1, 2, \ldots$, an sequence of non-negative integers with no gaps
* $s(l)$: ordered unique value of $t_{i,j}$, thus $s(0) < s(1) < s(2) < \ldots$
* $d(l)$: # of events occurred at $s(l)$
* $N(l)$: # of total events statisfying $t_{i,j} \leq s(l) \leq y_i, \forall i$  
  that is, all events occurred before $s(l)$.

Furthermore, we can estimate $\hat\Lambda(T_0)$ based on this random variable. Their relationship can be stated as
$$
\hat\Lambda(T_0) = \frac1n\sum^n_{i=1}m_i\hat{F}^{-1}(Y_i)
$$

* $n$: # of total patients
* $m_i$: # of recurrent time events before $Y_i$
* $Y_i$: censoring time between $[0, T_0]$, defined by  
  $$Y_i = \min[Y_{i0}^*, Y_{i1}^*]$$  
    * $Y_{i0}^*$: noninformative censoring, e.g., end of study
    * $Y_{i1}^*$: informative censoring, e.g., death, corelating with $N_i(\cdot)$

Example
-------

Part of an example using first 3 subjects in **Counting Process (CP)** format:

sub. $i$ | event $j$ | event/censor(1/0) | start | end | $\mathbb{X} = x_1, \ldots$
:------: | :-------: | :---------------: | :---: | :-: | :------------------------: 
1 | 1 | 1 | 0 | 2 | ... 
1 | 2 | 1 | 2 | 5 | ... 
1 | 3 | 0 | 5 | 8 | ... 
2 | 1 | 1 | 0 | 3 | ...
2 | 2 | 1 | 3 | 4 | ...
2 | 3 | 1 | 4 | 7 | ...
2 | 4 | 0 | 7 | 10 | ...
3 | 1 | 1 | 0 | 5 | ...
3 | 2 | 0 | 5 | 6 | ...

Thus all failure(event) time are ${2, 5, 3, 4, 7, 5}$.
And all censor time are ${8, 10, 6}$

**Transform** the data based on the ordered event $s(l)$

* $q(l)$: # of censored subjects with censored time $Y_i$ such that $s(l) < Y_i \leq s(l+1)$ 

$l$ | $s(l)$ | $d(l)$ | $q(l)$ | $N(l)$ | # of sub. left in exp
:-- | :----: | :----: | :----: | :----: | :-------------------:
0 | 0 | 0 | 0 | 0 | 3
1 | 2 | 1 | 0 | 1 | 3
2 | 3 | 1 | 0 | 2 | 3  
3 | 4 | 1 | 0 | 3 | 3 
4 | 5 | 2 | 1 | 5 | 3 
5 | 7 | 1 | 2 | 6 | 2
Inf | Inf | - | - | - | 0

Based on the estimator $\hat{F}(t)$ previously defined, the numerical value along time $t$ can be derived

$$
\begin{align*}
\hat{F}(t=1) = \prod_{s(l) > t = 1}(\cdot) &= \prod_{l \in \{1, 2, \ldots, 5\}}(1-\frac{d(l)}{N(l)}) = (1 - \frac11)(1-\frac12)(1-\frac13)(1-\frac25)(1-\frac16) = 0 \\\\
\hat{F}(t=2) &= \prod_{l \in \{2, \ldots, 5\}}(1-\frac{d(l)}{N(l)}) = (1-\frac12)(1-\frac13)(1-\frac25)(1-\frac16) \\\\
\hat{F}(t=3) &= \prod_{l \in \{3, 4, 5\}}(1-\frac{d(l)}{N(l)}) = (1-\frac13)(1-\frac25)(1-\frac16)  \\\\
\hat{F}(t=4) &= \prod_{l \in \{4, 5\}}(1-\frac{d(l)}{N(l)}) = (1-\frac25)(1-\frac16)  \\\\
\hat{F}(t=5) = \hat{F}(t=6) &= \prod_{l = 5}(1-\frac{d(l)}{N(l)}) = 1-\frac16  \\\\
\hat{F}(t=7) &= 1  \\\\
\end{align*}
$$

Demo R code
===========

We have contsructed an inhomogeneous Poisson random process generator, which accepts a positive function $\lambda(t)$ as its event intensity function. The test for this generator is in file `tests/gen_inhomo_poisson.R`.

```{r initial, echo=FALSE }
# implemtent by the method based on "Acceptance Rejection"
gen_inhomo_poisson <- function(lambda, T_0) {
  result <- c()
  # give bound of lambda(t)
  # 0 < lambda(t) <= lambda_u
  lambda_u <- optimize(lambda, c(0, T_0), maximum = TRUE)$objective
  t <- 0
  while(t <= T_0) {
    u <- runif(1)   # u1: Uniform(0,1)
    t <- t - log(u) / lambda_u
    if (t > T_0) break
    u2 <- runif(1)  # u2: Uniform(0,1)
    # the chance p to keep generated t
    # if lambda(t) == lambda_u, p = 1 >= u2 (Uniform(0,1))
    # t will be definitely kept
    if (u2 <= lambda(t)/lambda_u) result <- append(result, t)
  }
  result
}
```

In model, it assumes that recurrent events $X_i$ follow inhomogeneous Poisson random process, thus we use this generator to test the correctness of our model implementation.

We set the rate function of the inhomo. Posssion random process to be $\lambda(t) = e^{\sin(t) - 1}$. Time interval of interest is set to be $[0, 30]$ (`tau` = 30), same as the experiment end time `T_0`.

```{r setup}
T_0 <- 30   # experiment end time
tau <- T_0  # [0, tau] = time interval of interest
lambda.fun <- function(t) exp(sin(t) - 1)  # rate function of inhomo. Poisson
```

By looking at events of an observation generated from the Poisson process, some properties should be stated in the first place.

```{r}
set.seed(2)
obs <- gen_inhomo_poisson(lambda.fun, T_0)
obs
```

In real life, events ocurred in $[t, t+1]$ will be treated as one event, recorded the event time in integer. The following is what we will collect into our data.

```{r}
ceiling(obs)  # to interger time t
unique(ceiling(obs))  # what appears in data records 
```

However in `tests/gen_inhomo_poisson.R`, it shows that `unique(ceiling(events))` does distort the distribution. So we come up two approaches: continuous and discrete time in further investigation.


Continuous Time (For Validation and Testing)
------------------------------------------------

We need a undistorted or less distorted sampling to validate our model implementation.

In continuous time approach, we view evenet time as non-integer (or decimals), so $t$ can be the following cases:

$$
\begin{align*}
t &= 0, 1, 2, \ldots\\\\
t &= 0.0, 0.1, 0.2, \ldots, 1.0, 1.1, 1.2, \ldots\\\\
\end{align*}
$$

As the digit of event time increases, the more we can fit the generated data to its intensity function.

First we generate $x_i$, sequences of event time for all 500 observations/patients.

```{r}
library(plyr, quietly=TRUE)
x.N <- 500  # number of observations/patients
x.seq <- rlply(x.N, gen_inhomo_poisson(lambda=lambda.fun, T_0=T_0))
```

However in this model with no covariates, the intensity(rate) function is invariant of observation($i$), so we combine all events together and sort by the order of event time.

```{r}
x.merged <- sort(unlist(x.seq))  # merge all events and sort
```

If we treat event time as integer and an event ouccurs at $t$, it will be recorded as $k \leq t < k+1$, where $k$ is an integer. 

Similarily, if we treat event time as $t = 0.1, 0.2, 0.3, \ldots$, an event time $t$ will be recored as $k \leq t < k + 0.1$, where $k$ has one decimal digit.


```{r}
# same function as ceiling but digit sensitive
table(round(x.merged[1:1000] + 0.5, digits=0))
time.digit <- 1  # 0: integer, 1: with 1 decimals, ...
table(round(x.merged[1:1000] + 5 * 10^(-time.digit-1), digits=time.digit))
```

First we treat these event time as interger, but leave room to adjust the digit to be rounded. 

Events ouccurred in same time interval will be collected by `table()`, wich is $d(l)$ in the model. $l$ will be the column index of $d$ and $s(l)$ will be the column name of $d$. $N(l)$ is then the cumulative sum of $d(l)$.

```{r}
time.digit <- 0  # 0: integer, 1: with 1 decimals, ...
x.merged <- round(x.merged + 5 * 10^(-time.digit-1), digits=time.digit)
d <- table(x.merged)
s <- as.numeric(names(d))
N <- cumsum(d)
```

Finally we are ready to compute $\hat{F}(t) = \prod_{s(l) > t}(1-\frac{d(l)}{N(l)})$. If one is familiar with how R computes vector, one should skip the following step-by-step demonstration.

We use $t=6$ here to show how to compute $\hat{F}(t)$ out. Note that `d, N, s` are vectors with same length. `s > 6` is a vector contains `TRUE` or `FALSE` based on the condition `s > 6` of each element and `some_vec[s > 6]` picks the ones that are specified as `TRUE`. 

```{r}
d[s > 6]
N[s > 6]
1 - d[s > 6] / N[s > 6]
prod(1 - d[s > 6] / N[s > 6])
```

To obtain $\hat{F}(t)$ For a series of t, `sapply()` will do the trick. Also, theoretical value of $F(t)$ and $\Lambda(t)$ is computed. 

```{r}
F.hat <- function(t_seq) {
  sapply(t_seq, function(t) prod(1 - d[s > t] / N[s > t]))
}

Lambda.fun <- function(t) {
  sapply(t, function(t) integrate(lambda.fun, 0, t)$value)
}

F.fun <- function(t) {
  sapply(t, function(t) Lambda.fun(t) / Lambda.fun(T_0))
}
```

Finally $F(t)$ and $\hat{F}(t)$ can be plotted:

```{r}
curve(F.fun, 0, tau, col = 2)   # theoretical curve in red
curve(F.hat, 0, tau, add=TRUE)  # obtained from generated data
```

By increasing the digit of event time, two curves can be more fitted.

```{r}
time.digit <- 1  # 0: integer, 1: with 1 decimals, ...
```


```{r, echo=FALSE}
x.merged <- sort(unlist(x.seq))  # merge all events and sort
x.merged <- round(x.merged + 5 * 10^(-time.digit-1), digits=time.digit)
d <- table(x.merged)
s <- as.numeric(names(d))
N <- cumsum(d)
curve(F.fun, 0, tau, col = 2)
curve(F.hat, 0, tau, add=TRUE)
```


Generate censor time $y_i$:
TODO

TODO
====
* put in censor time
* bootstrapping
* add $z_i$